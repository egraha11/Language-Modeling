{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136abbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, LSTM, Flatten, Dropout, RNN, Embedding\n",
    "from keras.models import Sequential\n",
    "#from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fb6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text\n",
    "\n",
    "text = (open(\"wonderland.txt\", encoding=\"utf8\").read()).lower()\n",
    "\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584a9e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3037\n"
     ]
    }
   ],
   "source": [
    "#text tokenization \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "\n",
    "res = text_to_word_sequence(text)\n",
    "\n",
    "\n",
    "words = set(res)\n",
    "vocab_size = len(words)\n",
    "\n",
    "print(vocab_size)\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af8077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape data into input/output ngrams\n",
    "x=[]\n",
    "y=[]\n",
    "sequence_len = 4\n",
    "\n",
    "for word in range(len(res)-sequence_len):\n",
    "    x.append(res[word:word+sequence_len])\n",
    "    y.append(res[word+sequence_len])\n",
    "    \n",
    "#print(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355942d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text/character mapping using one hot encoding or vectorization\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "vectorize_layer = TextVectorization(max_tokens=vocab_size,\n",
    "                                    split='whitespace',\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=sequence_len)\n",
    "\n",
    "vectorize_layer.adapt(res) \n",
    "\n",
    "#print(vectorize_layer.vocabulary_size())\n",
    "#print(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469801ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoded = []\n",
    "\n",
    "for seq in x:\n",
    "    #convert each sequence represesented as a list into a string\n",
    "    seq = \" \".join(seq)\n",
    "    \n",
    "    encoded = vectorize_layer(seq)\n",
    "    #print(seq)\n",
    "    #print(encoded)\n",
    "    \n",
    "    x_encoded.append(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6386df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3037\n",
      "27571\n",
      "27571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#manually map words to int\\nword_to_int_map = {word:ind for ind,word in enumerate(words)}\\nint_to_word_map = {ind:word for ind,word in enumerate(words)}\\n\\ny_modified = []\\n\\nfor word in y:\\n    y_modified.append(word_to_int_map[word])\\n\\ny_modified = to_categorical(y_modified)\\n\\nprint(len(y_modified[1]))\\nprint(len(y_modified))\\nprint(len(x))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encode target\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_modified = []\n",
    "\n",
    "for word in y:\n",
    "    try:\n",
    "        y_modified.append(vectorize_layer.get_vocabulary().index(word))\n",
    "    except Exception as e:\n",
    "        y_modified.append(vectorize_layer.get_vocabulary().index(\"[UNK]\"))\n",
    "\n",
    "y_modified = to_categorical(y_modified)\n",
    "\n",
    "print(len(y_modified[1]))\n",
    "print(len(y_modified))\n",
    "print(len(x))\n",
    "\n",
    "\"\"\"\n",
    "#manually map words to int\n",
    "word_to_int_map = {word:ind for ind,word in enumerate(words)}\n",
    "int_to_word_map = {ind:word for ind,word in enumerate(words)}\n",
    "\n",
    "y_modified = []\n",
    "\n",
    "for word in y:\n",
    "    y_modified.append(word_to_int_map[word])\n",
    "\n",
    "y_modified = to_categorical(y_modified)\n",
    "\n",
    "print(len(y_modified[1]))\n",
    "print(len(y_modified))\n",
    "print(len(x))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca903ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egrah\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#create embedding layer\n",
    "embedding_dim = 10\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f032485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egrah\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 15ms/step - loss: 6.5063\n",
      "Epoch 2/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 6.0051\n",
      "Epoch 3/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 16ms/step - loss: 5.7915\n",
      "Epoch 4/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 15ms/step - loss: 5.5376\n",
      "Epoch 5/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 5.3789\n",
      "Epoch 6/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - loss: 5.1923\n",
      "Epoch 7/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - loss: 5.0170\n",
      "Epoch 8/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - loss: 4.8806\n",
      "Epoch 9/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - loss: 4.7521\n",
      "Epoch 10/10\n",
      "\u001b[1m2758/2758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 4.6108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17b2b3612d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model\n",
    "\n",
    "#convert list of tensorflow objects to numpy array \n",
    "x_encoded = np.array(x_encoded)\n",
    "\n",
    "#embedding_layer(x_encoded)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(LSTM(100, input_shape=(x_encoded.shape[1], embedding_dim), return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(y_modified.shape[1], activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "model.fit(x_encoded, y_modified, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2789e906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use', 'to', 'marmalade”', 'of', 'a']\n"
     ]
    }
   ],
   "source": [
    "#test by generating random text\n",
    "import random \n",
    "\n",
    "test_len=5\n",
    "\n",
    "generated = []\n",
    "\n",
    "#generate random seed to begin testing\n",
    "x = np.array(random.choice([num for num,text in enumerate(vectorize_layer.get_vocabulary())])).reshape(-1, 1)\n",
    "\n",
    "for word in range(test_len):\n",
    "    #reshape prediction so model excepts a single input value\n",
    "    x_padded = pad_sequences(x, maxlen=4)\n",
    "    \n",
    "    preds = list(model.predict(x_padded, verbose=0)[0])\n",
    "    \n",
    "    index = preds.index(max(preds))\n",
    "    \n",
    "    #retreive predicted word\n",
    "    generated.append(vectorize_layer.get_vocabulary()[index])\n",
    "    \n",
    "    #re-initialize next word that goes into the model\n",
    "    x=index\n",
    "    x=np.array(index).reshape(-1,1)   \n",
    "    \n",
    "#print generated text\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499efeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
